# (c) 2016 DataNexus Inc.  All Rights Reserved.
# Licensed software not for distribution
#
#
---
- import_tasks: tune.yml

- import_tasks: interface-facts.yml

- set_fact: 
    connect_user: "{{ (apache_kafka) | ternary(connect.distributed.apache.user, connect.distributed.confluent.user) }}"

- set_fact: 
     connect_group: "{{ (apache_kafka) | ternary(connect.distributed.apache.group, connect.distributed.confluent.group) }}"
  
- set_fact: 
    connect_service_name: "{{ (apache_kafka) | ternary(connect.distributed.apache.service_name, connect.distributed.confluent.service_name) }}"

- set_fact: 
    connect_config_file: "{{ (apache_kafka) | ternary(connect.distributed.apache.config_file, connect.distributed.confluent.config_file) }}"

- set_fact: 
    connect_path: "{{ (got_root | default('yes')) | ternary('/usr/bin', (confluent_root + '/confluent-' + confluent.packages.confluent_version + '.' + confluent.packages.minor_release.split('-')[0] + '/bin')) }}"
    
- block:
  
  # cap number of brokers in config at 5
  - name: KAFKA OVERLAY (CONNECT) | configuring bootstrap servers for {{ connect_service_name }}
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^bootstrap.servers='
      line: "bootstrap.servers={{ groups['kafka_public'][:5] | join(':' + kafka.config.broker_port + ',') }}:{{ kafka.config.broker_port }}"
    notify: restart connect
    
  - name: KAFKA OVERLAY (CONNECT) | configuring cluster group id for {{ connect_service_name }}
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^group.id='
      line: "group.id={{ connect.distributed.config.group_id }}"
    notify: restart connect
        
  - name: KAFKA OVERLAY (CONNECT) | configuring key converter for {{ connect_service_name }}
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^key.converter='
      line: "key.converter={{ connect.distributed.config.key_converter }}"
    notify: restart connect
        
  - name: KAFKA OVERLAY (CONNECT) | configuring value converter for {{ connect_service_name }}
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^value.converter='
      line: "value.converter={{ connect.distributed.config.value_converter }}"
    notify: restart connect
            
  - name: KAFKA OVERLAY (CONNECT) | configuring key converter schema enablement for {{ connect_service_name }}
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^key.converter.schemas.enable='
      line: "key.converter.schemas.enable={{ connect.distributed.config.key_converter_schemas_enable }}"
    notify: restart connect
            
  - name: KAFKA OVERLAY (CONNECT) | configuring value converter schema enablement for {{ connect_service_name }}
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^value.converter.schemas.enable='
      line: "value.converter.schemas.enable={{ connect.distributed.config.value_converter_schemas_enable }}"
    notify: restart connect
        
  - name: KAFKA OVERLAY (CONNECT) | configuring storage offset topic for {{ connect_service_name }}
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^offset.storage.topic='
      line: "offset.storage.topic={{ connect.distributed.config.offset_storage_topic }}"
    notify: restart connect
        
  - name: KAFKA OVERLAY (CONNECT) | configuring storage offset topic replication factor for {{ connect_service_name }}
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^offset.storage.replication.factor='
      line: "offset.storage.replication.factor={{ connect.distributed.config.offset_storage_replication_factor }}"
    notify: restart connect
        
  - name: KAFKA OVERLAY (CONNECT) | configuring storage offset topic for {{ connect_service_name }}
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^config.storage.topic='
      line: "config.storage.topic={{ connect.distributed.config.config_storage_topic }}"
    notify: restart connect
        
  - name: KAFKA OVERLAY (CONNECT) | configuring storage offset topic replication factor for {{ connect_service_name }}
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^config.storage.replication.factor='
      line: "config.storage.replication.factor={{ connect.distributed.config.config_storage_replication_factor }}"
    notify: restart connect
        
  - name: KAFKA OVERLAY (CONNECT) | configuring status storage topic for {{ connect_service_name }}
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^status.storage.topic='
      line: "status.storage.topic={{ connect.distributed.config.status_storage_topic }}"
    notify: restart connect
        
  - name: KAFKA OVERLAY (CONNECT) | configuring status storage topic replication factor for {{ connect_service_name }}
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^status.storage.replication.factor='
      line: "status.storage.replication.factor={{ connect.distributed.config.status_storage_replication_factor }}"
    notify: restart connect
        
  - name: KAFKA OVERLAY (CONNECT) | configuring offset flush interval for {{ connect_service_name }}
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^offset.flush.interval.ms='
      line: "offset.flush.interval.ms={{ connect.distributed.config.offset_flush_interval_ms }}"
    notify: restart connect

  - name: KAFKA OVERLAY (CONNECT) | enabling and configuring ReST host for {{ connect_service_name }}
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^rest.host.name='
      line: "rest.host.name={{ connector_rest_interface_ipv4 }}"
      insertafter: '^#rest.host.name='
    notify: restart connect

  - name: KAFKA OVERLAY (CONNECT) | enabling and configuring ReST port for {{ connect_service_name }}
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^rest.port='
      line: "rest.port={{ connect.distributed.config.rest_port }}"
      insertafter: '^#rest.port='
    notify: restart connect
        
  - name: KAFKA OVERLAY (CONNECT) | configuring kafka connect properties for consumer interceptors for control center
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^consumer.interceptor.classes='
      line: 'consumer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor'
    when:
      - groups['controlcenter'] is defined
      - groups['controlcenter'] | length > 0
    notify: restart connect

  - name: KAFKA OVERLAY (CONNECT) | configuring kafka connect properties for producers interceptors for control center
    lineinfile:
      path: "{{ connect_config_file }}"
      regexp: '^producer.interceptor.classes='
      line: 'producer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor'
    when:
      - groups['controlcenter'] is defined
      - groups['controlcenter'] | length > 0
    notify: restart connect
  
  - name: KAFKA OVERLAY (CONNECT) | ensuring {{ connect.distributed.user_service }} exists
    file:
      path: "{{ connect.distributed.user_service }}"
      owner: "{{ connect_user }}"
      group: "{{ connect_group }}"
      state: directory
      mode: 0755
  
  # this is a little odd because we either need to be root or the connect_user
  - name:  KAFKA OVERLAY (CONNECT)  | ensuring {{ (got_root | default('yes')) | ternary('/var/run', (confluent_root + '/var/run')) }} exists
    file:
      path: "{{ (got_root | default('yes')) | ternary('/var/run', (confluent_root + '/var/run')) }}"
      owner: "{{ (got_root | default('yes')) | ternary('root', connect_user) }}"
      group: "{{ (got_root | default('yes')) | ternary('root', connect_group) }}"
      state: directory
      mode: 0755
      
  - name: KAFKA OVERLAY (CONNECT) | ensuring {{ connect.distributed.environment.LOG_DIR }} exists
    file:
      path: "{{ connect.distributed.environment.LOG_DIR }}"
      owner: "{{ connect_user }}"
      group: "{{ connect_group }}"
      state: directory
      mode: 0755
      
  # this is datanexus original logging, so we need to make sure it exists since it's not handled via standard install
  - name: KAFKA OVERLAY (CONNECT) | ensuring {{ connect.distributed.environment.LOG_DIR }}/connect.log exists
    file:
      path: "{{ connect.distributed.environment.LOG_DIR }}/connect.log"
      owner: "{{ connect_user }}"
      group: "{{ connect_group }}"
      state: touch
      mode: 0644
  
  - set_fact: 
      connect_wrapper: "{{ (apache_kafka) | ternary('apache.connect.j2', 'confluent.connect.j2') }}"
      
  - name: KAFKA OVERLAY (CONNECT) | installing {{ connect_service_name }} into {{ connect.distributed.user_service }}
    template:
      src: "{{ connect_wrapper }}"
      dest: "{{ connect.distributed.user_service }}/kafka-connect"
      mode: 0755
      owner: "{{ connect_user }}"
      group: "{{ connect_group }}"
    
  # the thinking here is that these files are either restricted or not and that drives our escalation  
  become: "{{ got_root | default('yes') }}"
  
- block:
  
  - block:
        
    - name: KAFKA OVERLAY (CONNECT) | installing systemd {{ connect_service_name }} script
      template:
        src: apache-connect.service.j2
        dest: "/etc/systemd/system/{{ connect_service_name }}.service"
        mode: 0640
        owner: "{{ connect_user }}"
        group: "{{ connect_group }}"
      notify:
        - reload systemd
      when: 
        - ansible_distribution_version is version_compare('7', '>=')
        
    - name: KAFKA OVERLAY (CONNECT) | installing sysvinit {{ connect_service_name }} script
      template:
        src: apache-connect.sysvinit.j2
        dest: "/etc/init.d/{{ connect_service_name }}"
        mode: 0755
        owner: root
        group: root
      when: 
        - ansible_distribution_version is version_compare('7', '<')
        
    when:
      - apache_kafka
      - not confluent_kafka
      
  - set_fact: 
      connect_override_name: "{{ (apache_kafka) | ternary(connect.distributed.apache.systemd_override, connect.distributed.confluent.systemd_override) }}"
      
  - name: KAFKA OVERLAY (CONNECT) | creating systemd override directory
    file:
      path: "{{ connect_override_name }}"
      owner: "{{ connect_user }}"
      group: "{{ connect_group }}"
      state: directory
      mode: 0750
    when: 
      - ansible_distribution_version is version_compare('7', '>=')
      
  - set_fact:
      connect_override_name: "{{ (apache_kafka) | ternary(connect.distributed.apache.systemd_override, connect.distributed.confluent.systemd_override) }}"
   
  - name: KAFKA OVERLAY (CONNECT) | installing {{ connect_service_name }} environment overrride
    template:
      src: environment.j2
      dest: "{{ connect_override_name }}/override.conf"
      mode: 0640
      owner: "{{ connect_user }}"
      group: "{{ connect_group }}"
    notify:
      - reload systemd
      - restart connect
    when: 
      - ansible_distribution_version is version_compare('7', '>=')
      
  - name: KAFKA OVERLAY (CONNECT) | enabling {{ connect_service_name }} by systemd
    systemd:
      name: "{{ connect_service_name }}"
      enabled: yes
    when:
      - ansible_distribution_version is version_compare('7', '>=')
  
  - name: KAFKA OVERLAY (CONNECT) | installing sysvinit {{ connect_service_name }} script
    template:
      src: confluent.sysvinit.j2
      dest: "/etc/init.d/{{ connect_service_name }}"
      mode: 0755
      owner: root
      group: root
    when: 
      - ansible_distribution_version is version_compare('7', '<')
      
  - name: KAFKA OVERLAY (CONNECT) | enabling {{ connect_service_name }} by svsvinit
    sysvinit:
      name: "{{ connect_service_name }}"
      enabled: yes
    when:
      - ansible_distribution_version is version_compare('7', '<')
      
  become: yes
  when:
    - got_root | default('yes') 
    - ansible_distribution == 'CentOS' or ansible_distribution == 'RedHat'
